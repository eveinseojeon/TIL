## 머신러닝의 기본 개념 및 방법론의 분류

머신러닝



머신러닝 - 지도학습, 비지도학습, 강화학습



지도학습 - X, Y가 둘 다 있음

비지도학습 - X만 있음



지도학습 (Supervised Learning)

: x에 대한 y라벨이 주어져 있는 훈련용 데이터에서 x와 y의 관계를 표현하는 함수를 찾아 목표변수인 라벨을 예측하도로 모델을 학습.

y라벨의 데이터 타입에 따라 회귀(regression), 분류(classification)로 나뉨.

- 회귀 : y라벨이 연속형. x에 따른 y의 예측값을 찾는 직선 찾기
- 분류 : y라벨이 범주형. y값들을 분리하는 경계 찾기



대표 알고리즘

- 회귀 : Linear regression
- 분류 : k-nearest neighbors, Logistic regression, softmax regression, Naive Bayesian
- 회귀, 분류 모두 가능 : decision tree, SVM, Random forest, Boosting, Neural Network, Deep learning





비지도학습 (Unsupervised Learning)

: y라벨이 없는 훈련용 데이터에서 x들만 모아놓고 특징 변수들 간의 관계나 유사성을 기반으로 의미있는 패턴을 학습, 추출. 자율학습이라고도 함.

군집화(clustering), 차원축소(dimension reduction), 추천 시스템(recommendation) 등에 활용됨. 

- 군집화 : 특징 변수들의 유사성을 기준으로 없던 라벨을 불여주기
- 차원축소 : 특징 변수들이 너무 많을 때는 예측 모형을 만들려고 해도 모델링이 잘 안 되고, 데이터의 패턴을 찾기도 힘들다. 이 때 특징 변수들만 모아서 차원 축소를 한다. 차원축소의 기본 원리는 모든 특징 변수들이 가진 정보를 최대한 반영하되 소수의 특징 변수만 남기겠다는 것. 해석을 풍부하게 하고 예측력을 높일 수 있다. 지도학습에서 y라벨이 있을 때도, 특징 변수들과 y라벨의 2차원 시각화를 위해 차원축소를 사용할 수도 있음.
- 추천 시스템



대표 알고리즘

- 군집화 : k-means clustering, hierarchical clustering
- 차원축소 : PCA(principal component analysis: 주성분 분석), LDA, t-SNE
- 추천 시스템 : Apriori

Auto-Encoders





강화학습

: 행동하는 주체(agent)가 있고 어떤 정책(policy)에 따라 행동(action)을 했을 때의 상태(state)와 보상(reward)을 바꿔주는 환경(environment)으로 구성됨. 주체가 매번 어떤 행동을 하면 환경에 의해 상태와 보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 계속 학습해 나가게 됨. 정책도 계속 변함.



대표 알고리즘

: SARSA, Q-Learning



## 머신러닝 모델의 검증 및 평가



과대적합(overfitting)

: 복잡한 알고리즘을 사용하여 데이터를 훈련하는 경우 과대적합 문제를 항상 염두에 두어야 함.



모델 적합에 사용된 자료를 평가를 위해 재활용하지 않고, 평가만을 위한 데이터를 확보할 필요가 있음.

-> 훈련자료 중 일부를 떼어놓는 것. 떼어놓은 것은 훈련에 사용하지 않는다.





모델 검증 및 평가를 위한 데이터의 구분 - Hold-out 방식, K-fold 교차검증(Cross-validation) 방식



Hold-out 방식

: 주어진 자료를 다음의 세 그룹으로 랜덤하게 분할한 뒤 주어진 목적에 따라 각각 모델의 훈련, 검증, 평가에 활용한다.

- 훈련 데이터(training data) : 모델의 학습을 위해 사용되는 자료. x에 따른 y=f(x)를 찾기. 매개변수 조정
- 검증 데이터(validation data) : 훈련 데이터 중에서 또 따로 떼어서, 훈련 데이터로 적합되는 모델을 최적의 성능으로 튜닝하기 위해 사용되는 자료. 초매개변수 조정 또는 특징 변수 선택(feature variable selecting?) 등에 이용
- 평가 데이터(test data) : 훈련, 검증 데이터로 적합된 최종 모델이 미래에 주어질 새로운 데이터에 대하여 얼마나 좋은 성과를 낼지 평가하는 데 사용되는 자료



평가 데이터를 가지고 Accuracy test 등을 수행할 수 있음.

일반적으로 평가 데이터의 accuracy는 훈련 데이터의 accuracy보다 낮다

조금만 작으면 괜찮은데 이 차이가 크다면 과대적합



K-fold(다중) 교차검증(Cross-validation) 방식

: 자료의 수가 충분하지 않은 경우에는 훈련 데이터에서 너무 많은 양의 데이터를 검증, 평가 데이터에 뺏기지 않도록, 교차검정(Cross-validation) 기법을 사용한다.

보통은 5-fold, 10-fold를 많이 쓴다.

데이터를 k개 그룹으로 분할한 뒤, k-1개 그룹의 데이터로 학습, 1개 데이터로 평가하는 것을 k번 반복. 그렇게 구한 loss 또는 accuracy의 평균으로 모델을 검증, 평가하는 것이다.

계산량이 많아서 훈련하는 데 시간이 많이 걸리는 단점이 있지만, 어쨌든 가진 데이터를 한 번씩은 다 활용할 수 있다는 장점이 있다.





과대적합과 과소적합의 밸런스를 잘 맞춰야 한다.

이 밸런스를 맞출 때 알아야 하는 것

일반화 오차 및 편향-분산 트레이드 오프



편향-분산 트레이드 오프(Bias-Variance Trade off)

: 모델의 복잡도에 따라 훈련 데이터와 평가 데이터의 예측오차는 일반적으로 아래와 같은 패턴을 보이게 됨.

Prediction Error(Test Error rate)는 모델이 너무 단순해도, 모델이 너무 복잡해도 높아진다.

- 편향(bias) : 정확도 개념. 표본 데이터가 달라질 때마다 모델도 조금씩 바뀌는데 모델들의 평균이 실제 자료의 패턴을 얼마나 잘 맞추느냐를 나타낸다. 단순한 모델은 편향이 높고, 복잡한 모델은 편향이 낮다.
- 분산(variance) : 변동성 개념. 표본 데이터가 달라지면 모델이 얼마나 크게 바뀌는가를 나타낸다. 단순한 모델은 분산이 낮고(표본이 달라져도 단순한 직선 모델은 크게 달라지진 않고 기울기, 절편 살짝씩만 달라진다), 복잡한 모델은 분산이 높다(표본이 달라지면 복잡한 모델은 크게 달라진다).



일반화 오차 = 편향2 + 분산

모델이 단순하면 편향이 높아서 일반화 오차가 커지고,

모델이 복잡하면 분산이 높아서 일반화 오차가 커지는 것이다.

-> 즉, 편향도 낮으면서 분산도 낮은 지점을 찾아야 한다.



과대적합(모델 너무 복잡)을 막기 위해서는?

- 훈련 데이터를 많이 확보 (변동성 줄이기)
- 모델의 복잡도를 낮추기(단순화) : 특징 변수의 수를 줄이거나 차원축소, 파라미터에 규제 적용(Ridge, Lasso, Elasic Net 등의 방법)



## 머신러닝 모델의 평가지표

 회귀 모델의 평가 지표 - RMSE, 결정계수(R2: R-square), MAE, MAPE

RMSE(Root mean square error)

: MSE(오차 제곱의 평균)의 제곱근

실제값과 예측값의 차이(오차)의 평균

작을수록 좋다



결정계수(R\**2)

: 0~1 사이의 값

데이터 점들이 우리 모델로 얼마나 잘 요약되고 있는가를 나타냄

0이면 모델이 매우 안 좋은 상태고, 1이면 모델이 완벽히 피팅한 상태(오차가 0)

클수록 좋고 1에 가까우면 좋다



MAE(mean absolute error)

: RMSE는 제곱했다가 제곱근 취한 건데,

MAE는 그냥 절댓값을 취해서(오차의 부호를 제거) 이를 평균한 값

MAE가 10이면 오차가 평균적으로 10 정도 발생한다고 이해



MAPE(mean average percentage error)

실제 값 대비 오차가 차지하는 비중이 평균적으로 얼만지 확인



MAE, MAPE 둘 다 ‘오차의 평균’ 개념이기 때문에 작을수록 좋다



 분류 모델의 평가 지표 - 정오분류표, ROC 도표

정오분류표(교차분류표: confusion matrix)

- 정확도, 정분류율(accuracy) : 전체 중 잘 맞춘 것의 비중 = (TP + TN) / 전체
- 오분류율 : 전체 중 잘못 맞춘 것의 비중 = (FP + FN) / 전체
- 정밀도(precision) : positive로 예측한 것 중에서 실제 positive인 비중 = TP / (TP + FP). FP가 작으면 좋다. FP의 비용이 클 때 사용. ex) 스팸메일 분류
- 재현율(recall) = 민감도(sensitivity) : 실제 positive인 것 중에서 positive로 예측한 비중 = TP / (TP + FN). FN이 작으면 좋다. FN의 비용이 클 때 사용. ex) 암환자 진단

threshold(분류 기준점)가 증가하면 precision은 증가하고 recall은 감소한다.

precision과 recall은 반대로 간다.



ROC(Receiver operating characteristic) 도표

: TPR(민감도, sensitivity)과 FPR(특이도, specificity)의 조합을 도표로 나타냄

가로축이 FPR, 세로축이 TPR

FPR보다 TPR이 가파르게 증가해야 좋은 모델이다.

ROC 곡선이 초반에 급격히 상승하면 좋다.



AUC(Area Under the Curve)

: ROC 곡선 아래의 면적

1에 가까울수록 좋은 수치

FPR이 작을 때 얼마나 큰 TPR을 얻는지에 따라 결정됨



-> 어떤 관점에서 이 분류 문제를 바라보는가? 어떤 범주가 나에게 큰 비용을 발생시키는가? 어떻게 잘못 분류했을 때 큰 비용을 발생시키는가?

이에 맞게 적절한 평가 지표를 선택해야 한다. 


