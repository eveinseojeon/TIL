## 모평균 비교에 관한 가설검정: t-test

- 단일 표본 t검정

: 단일 모집단에서 추출된 하나의 표본집단이 대상. 모평균과 표본평균의 차이를 검정

(scipy) **ttest_1samp()** - 모집단의 평균은 popmean 인자에 지정

- 대응 표본 t검정

: 동일한 모집단으로부터 추출된 두 표본집단이 대상. 표본이 정규성을 만족하지 못하는 경우 Wilcoxon rank sum test 사용

(scipy) **ttest_rel()** - 검정을 실시하는 두 변수를 차례대로 지정

- 독립 2표본 t검정

: 보통 t-test라고 하면 이것으로, 비중이 꽤나 높음. 독립된 두 표본집단이 대상. 등분산 여부에 따라 검정통계량 계산식이 다름. 표본이 정규성을 만족하지 못하는 경우 Wilcoxon rank sum test 사용

(scipy) **ttest_ind()** - 검정을 실시하는 두 변수를 차례대로 지정. 등분산 가정을 만족하는 경우 equal_var 인자에 True를 할당

---

## 모평균 비교에 관한 가설검정: One way ANOVA

- 일원 분산 분석(One way ANOVA)

: scipy보다 statsmodels 사용 추천. 셋 이상의 여러 집단의 평균을 비교하는 것. 명목형 독립변수와 수치형 종속변수가 각각 1개일 때 실시하는 분석. 종속변수로 나뉘어지는 그룹이 2개 이상일 때 사용. 귀무가설을 기각하는 경우 사후 검정(Post-hoc) 실시. 사후 검정 방법으로는 Tukey's HSD, Duncan's MRT, Scheffe's test가 있음. 이는 모든 집단간 독립 2표본 t검정을 하는 것과 유사하며 어떤 집단간 평균이 유의하게 차이나는지 알 수 있음

(scipy) **f_oneway()** - 각각의 집단을 pd.Series로 입력

(statsmodels) **ols()** - 모델을 생성하고 적합. '종속변수~독립변수' 수식 입력 시 독립변수에 C() 함수 사용

(statsmodels) **anova_lm()** - 적합된 모델 정보를 기반으로 일원 분산 분석표를 보여줌

(statsmodels) **pairwise_tukeyhsd()** - 함수 내에 종속변수와 독립변수를 차례대로 선언. 결과 출력을 위해 반드시 print() 함수 사용. reject 변수의 True는 귀무가설을 기각한다는 의미

---

## 모분산 비교에 관한 가설검정: 등분산 검정(F-test of equality of variances)

- F-test

: 두 집단의 등분산 검정을 실시. 각 집단이 정규분포를 따를 때

(scipy) **f.cdf()** - F 검정통계량을 입력받아 p-value를 산출하는 함수. F 검정통계량, 첫번째 데이터의 자유도(dfd: len()-1), 두번째 데이터의 자유도(dfn: len())가 입력으로 필요

- Bartlett's test

: 두 집단 이상의 등분산 검정을 실시. 각 집단이 정규분포를 따를 때 -> ANOVA와 함께 쓰임

(scipy) **bartlett()**

- Levene's test

: 두 집단 이상의 등분산 검정을 실시. 각 집단이 정규분포를 따를 필요 X

(scipy) **levene()**

---

## 범주형 변수 간의 독립성 검정(Chi-squared test)

두 명목형 변수를 대상으로 실시하는 분석

독립 관점에서의 해석과 연관 관점에서의 해석이 존재한다. 귀무가설 채택(두 변수는 서로 독립이며 연관X) vs 귀무가설 기각(두 변수는 서로 독립이 아니며 연관 O)

연속형 변수의 경우 명목형 변수로 변환 후 실시

(scipy) **chi2_contingency()** - 두 개의 명목형 변수의 각 원소의 빈도를 입력한다(crosstab() 사용). 출력은 검정통계량, p-value, 자유도, 기대도수 이렇게 4개의 연산 결과가 튜플로 산출된다. correction 인자에 False 넣으면 연속성 수정을 적용하지 않음

---

## 상관분석

두 변수의 선형관계를 확인하기 위해 실시

상관계수가 0에 가까울수록 선형관계가 약하며, 절댓값이 1에 가까울수록 선형관계가 강함

|                                   | Quantitiative  | Ordinal                | Nominal          |
| --------------------------------- | -------------- | ---------------------- | ---------------- |
| **Quantitiative(수치형, 연속형)** | **Pearson's**  | Biserial               | Point Biserial   |
| **Ordinal(순서형)**               | Biserial       | **Spearman / Kendall** | Rank Biserial    |
| **Nominal(명목형)**               | Point Biserial | Rank Biserial          | Phi, L, C Lambda |

(pandas) **corr()** - 상관계수를 계산하는 데이터프레임 전용 메서드. method 인자에 'pearson', 'spearman',  'kendall'

(scipy) **pearsonr()** - Pearson 상관분석을 실시. 두 일차원 벡터를 입력으로 넣고, 상관계수와 p-value가 차례대로 출력

(scipy) **spearmanr()** - Spearman 상관분석을 실시. 두 일차원 벡터를 입력으로 넣고, 상관계수와 p-value가 차례대로 출력

(scipy) **kendalltau(**) - Kendall 상관분석을 실시. 두 일차원 벡터를 입력으로 넣고, 상관계수와 p-value가 차례대로 출력

---

## 단순 회귀분석(Simple Linear Regression)

연속형 종속변수와 독립변수 간 선형관계 및 설명력을 확인하는 기법

설명력과 오차평가지표로 모델의 성능을 평가

(statsmodels) **ols()** - 선형회귀분석을 위한 함수. ols() 함수 내에 종속변수와 독립변수를 선언. ols() 함수의 fit() 메서드로 모델 적합. 변수명에 온점(.) 등 특정 특수문자가 있는 경우 오류 발생. 모델 객체의 predict() 메서드로 예측(학습하지 않은 변수들도 함께 넣어도 편리하게 알아서 걸러준다). model.summary() 해서  F검정통계량에 대한 p-value, 즉 모델의 유의성을 검정한 값인 Prob(F-statistic)을 봤을 때 0.05보다 커서 귀무가설 기각 못하면 독립변수와 종속변수 간 선형관계가 만족되지 않는다는 것. 그럼 모델 버려야 함. 0.05보다 작으면 귀무가설 기각, 즉 선형관계를 만족한다는 것. 그 다음 R-squared(결정계수)와 Adj.R-squared(수정된/조정된 결정계수)가 1에 가까울수록 설명력이 좋은 모델. 또 독립변수의 t검정통계량에 대한 p-value P>|t| 부분을 확인했을 때 0.05보다 작으면 귀무가설을 기각하여 해당 변수의 coef(계수) 값이 통계적으로 유의하다는 뜻(0이 아님). 

<u>sklearn은 머신러닝 전문 라이브러리!</u>

(sklearn) **LinearRegression()** - 선형회귀분석을 위한 함수(ols()보다 강력한 기능을 가짐). LinearRegression() 함수 내 fit_intercept로 절편 적합 여부 설정 가능. LinearRegression() 함수의 fit() 메서드에 학습 데이터 할당 가능(이때 X 인자에 2차원 데이터프레임을 넣어줘야 함). 모델 객체의 coef_, intercept\_ 어트리뷰트로 각각 계수와 절편 확인 가능. 모델 객체의 predict() 메서드로 예측(이때도 predict() 안에 2차원 데이터프레임을 넣어줘야 함)

(sklearn) **mean_absolute_error()** - MAE 연산(모델 평가 함수)

(sklearn) **mean_squared_error()** - MSE 연산(모델 평가 함수). 해당 결과를 제곱하면 RMSE(Root Mearn Squared Error)

(sklearn) **train_test_split()** - train_size, random_state 인자

---

## 다중 회귀분석(Multiple Linear Regression)

연속형 종속변수와 두 개 이상의 독립변수 간 선형관계 및 설명력을 확인하는 기법

필요 시 모델 성능 향상을 위한 파생변수 생성 및 성능 비교 필요

명목형 변수가 독립변수인 경우 가변수 변환 후 모델 적합

* 다중공선성 문제

독립변수 간 강한 상관관계가 나타나는 문제. 상관계수를 확인하여 그 값이 높은 것을 사전에 제거. 회귀 모델 생성 이후 분산팽창계수(VIF) 확인하여 관련 변수(10 이상) 처리

(patsy) **dmatrices()** - 수식을 기반으로 데이터 행렬을 생성. y, X로 결과를 받음. 분산팽창계수 확인을 위해 입력 데이터를 전처리할 때 필요한 함수. return_type 인자에 'dataframe'으로 설정하면 후처리 용이 <- 데이터프레임에 corr() 함수 써서 상관계수 높은(다중공선성 문제가 있는) 변수들을 확인할 수도 있음

(statsmodels) **variance_inflation_factor()** - 분산팽창계수를 연산하기 위한 함수. 반복문 또는 list comprehension 사용

---

## 분류: 로지스틱 회귀분석(Logistic Regression)







---

## 의사결정나무 모델: 분류 및 회귀나무









