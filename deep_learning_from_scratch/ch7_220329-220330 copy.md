# 7. 합성곱 신경망(CNN)

---

- 합성곱 신경망(CNN: convolutional neural network)은 이미지 인식, 음성 인식 등 다양한 곳에서 사용되는데, 특히 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 다 CNN을 기초로 한다.



## 7.1. 전체 구조

- 지금까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있는 **완전연결**(fully-connected, 전결합)이었으며, 완전히 연결된 계층을 **Affine 계층**이라는 이름으로 구현했다.
- CNN에서는 새로운 '합성곱 계층(Conv)'과 '풀링 계층(Pooling)'이 추가되어, 이전의 'Affine-ReLU' 연결이 '<u>Conv-ReLU-(Pooling)</u>'으로 바뀜.
- 그런데 출력에 가까운 층에서는 이전의 'Affine-ReLU' 구성을 사용할 수 있고, 또 마지막 출력 계층에서는 'Affine-Softmax' 조합을 그대로 사용함.



## 7.2. 합성곱 계층

- 지금까지 본 완전연결 신경망에서 사용한 <u>완전연결 계층(Affine 계층)의 문제점은 '데이터의 형상이 무시'된다는 사실</u>이다. 모든 입력 데이터를 동등한 뉴런(같은 차원의 뉴런)으로 취급하므로 형상에 담긴 정보를 살릴 수 없다.
- 한편, <u>합성곱 계층은 데이터의 형상을 유지한다.</u> 3차원 데이터같이 입체적인 데이터로 입력받고 다음 계층에도 입체적인 데이터로 전달하여, 각 계층 사이에 입체적인 데이터가 흐른다. -> <u>CNN에서는 형상을 가진 데이터를 제대로 이해할 (가능성이 있는) 것</u>이다.
- CNN에서는 합성곱 계층의 입력 데이터는 **입력 특징 맵**(input feature map), 출력 데이터는 **출력 특징 맵**(output feature map)이라고 한다.

- 합성곱 계층에서 **합성곱 연산**을 처리하는데, 합성곱 연산은 이미지 처리에서 말하는 **필터 연산**에 해당된다.

  - 입력 데이터에 필터(커널)의 윈도우(window)를 일정 간격으로 이동해가며 적용하는데, 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구한다. 이 계산을 **단일 곱셈-누산**(FMA: fused multiply-add)이라 한다. 그 결과를 출력의 해당 장소에 저장한다.

  - CNN에서의 필터의 매개변수가 이전의 완전연결 신경망의 '가중치'에 해당하며, '편향'은 필터를 적용한 후의 데이터에 더해진다. 편향은 항상 (1*1)이다.

- **패딩**(padding): 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(예컨대 0)으로 채우는 기법

  - 주로 출력 크기를 조정할 목적으로 사용된다. 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달하기 위해서.

  - 패딩을 크게 하면 출력 크기가 커짐

- **스트라이드**(stride): 필터를 적용하는 위치의 간격

  - 스트라이드를 크게 하면 출력 크기가 작아짐

- 패딩, 스트라이드에 따른 출력 크기를 계산하는 방법

  | 입력 크기 | 필터 크기 | 패딩 | 스트라이드 | 출력 크기                |
  | --------- | --------- | ---- | ---------- | ------------------------ |
  | H         | FH        | P    | S          | OH = (H + 2P - FH)/S + 1 |
  | W         | FW        |      |            | OW = (W + 2P - FW)/S + 1 |

  - OH, OW 값이 정수로 나눠떨어지지 않을 때는 가장 가까운 정수로 반올림하는 등의 대응을 해준다.

- **3차원 데이터의 합성곱 연산**은 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻는다.

  - 주의할 점: <u>입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다.</u>

  - 3차원 데이터의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다.

  - 3차원 데이터를 다차원 배열로 나타낼 때는 (채널 C, 높이 H, 너비 W) 순으로 쓴다.

    | 입력 데이터 | *    | 필터        | ->   | 출력 데이터 |
    | ----------- | ---- | ----------- | ---- | ----------- |
    | (C, H, W)   |      | (C, FH, FW) |      | (1, OH, OW) |

  - 필터(가중치)를 FN개 적용하면 출력 데이터도 FN개의 채널을 내보낼 수 있다. 이렇듯 합성곱 연산에서는 필터의 수도 고려해야 한다. 따라서 필터의 가중치 데이터는 4차원 데이터이며 (필터의 개수=출력 채널 수, 입력 채널 수, 높이, 너비) 순으로 쓴다.

    | 입력 데이터 | *    | 필터                | ->   | 출력 데이터      |
    | ----------- | ---- | ------------------- | ---- | ---------------- |
    | (C, H, W)   |      | (**FN**, C, FH, FW) |      | (**FN**, OH, OW) |

  - 편향까지 더한 모습

    | 입력 데이터 | *    | 필터            | +    | 편향           | ->   | 출력 데이터  |
    | ----------- | ---- | --------------- | ---- | -------------- | ---- | ------------ |
    | (C, H, W)   |      | (FN, C, FH, FW) |      | **(FN, 1, 1)** |      | (FN, OH, OW) |

- 합성곱 연산도 **배치 처리**를 지원하고자, 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 (데이터 수, 채널 수, 높이, 너비) 순으로 저장한다. 데이터가 N개일 때 배치 처리한다면 데이터 형태가 아래처럼 된다.

  | N개의 입력 데이터                     | *    | 필터                                                 | +    | 편향                 | ->   | N개의 출력 데이터                     |
  | ------------------------------------- | ---- | ---------------------------------------------------- | ---- | -------------------- | ---- | ------------------------------------- |
  | (**N**, C, H, W)                      |      | (FN, C, FH, FW)                                      |      | (FN, 1, 1)           |      | (**N**, FN, OH, OW)                   |
  | (데이터 수, 입력 채널 수, 높이, 너비) |      | (필터의 개수=출력 채널 수, 입력 채널 수, 높이, 너비) |      | (출력 채널 수, 1, 1) |      | (데이터 수, 출력 채널 수, 높이, 너비) |

  - 데이터의 선두에 배치용 차원을 추가함
  - 데이터가 4차원 형상을 가진 채 각 계층을 타고 흐르게 됨
  - 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 이뤄진다. 즉, N회 분의 처리를 한 번에 수행하는 것이다.



## 7.3. 풀링 계층

- **풀링**(pooling): 세로, 가로 방향의 공간을 줄이는 연산
  - **최대 풀링**(max pooling): 대상 영역에서 최댓값을 취하는 연산 (이미지 인식 분야에서는 주로 최대 풀링을 사용한다.)
  - **최소 풀링**(min pooling): 대상 영역에서 최솟값을 취하는 연산
  - **평균 풀링**(average pooling): 대상 영역의 평균을 계산
- 보통 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정한다. (대상 영역이 겹치지 않도록)
- 풀링 계층의 특징
  - 학습해야 할 매개변수가 없다
  - 채널 수가 변하지 않는다
  - 입력의 변화에 영향을 적게 받는다 (강건하다)



## 7.4. 합성곱/풀링 계층 구현하기



## 7.5. CNN 구현하기



## 7.6. CNN 시각화하기



## 7.7. 대표적인 CNN

- LeNet : CNN의 원조
- AlexNet : 딥러닝이 주목받도록 이끎

