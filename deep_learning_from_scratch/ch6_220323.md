# 6. 학습 관련 기술들

---

- 신경망(딥러닝) 학습의 효율과 정확도를 높일 수 있는 기법들을 알아 보자.



## 6.1. 매개변수 갱신

- 신경망 학습의 목적은 손실 함수의 값을 가능한 한 낮추는 매개변수를 찾는 것인데 이는 곧 매개변수의 최적값을 찾는 문제이며, 이러한 문제를 푸는 것을 **최적화**(optimization)라 한다. <u>최적화를 담당하는 클래스를 분리해 구현하면 기능을 모듈화하기 좋다.</u>

### 6.1.2. 확률적 경사 하강법(SGD)

- 매개변수의 기울기(미분)를 구해, 기울어진 방향으로 매개변수 값을 갱신하는 일을 반복해서 점점 최적의 값에 다가가는 방법
- <u>지금 있는 장소에서 가장 크게 기울어진 방향으로 일정 거리만큼 가자!</u>
- SGD의 단점: 비등방성(anisotropy) 함수(방향에 따라 성질, 즉 여기에서는 기울기가 달라지는 함수)에서는 탐색 경로가 비효율적이다. ->  최솟값까지 지그재그로 이동
- 또한 SGD가 지그재그로 탐색하는 근본 원인은 기울어진 방향이 본래의 최솟값과 다른 방향을 가리켜서이다.
- SGD의 이러한 단점을 개선해 주는 대체 기법 아래 세 가지

### 6.1.4. 모멘텀(Momentum)

- 모멘텀은 '운동량'을 뜻하는 단어로, 물리와 관계가 있다.
- 기울기 방향으로 힘을 받아 가속되며 가기 (물리에서의 속도의 영향) -> <u>공이 그릇의 바닥을 구르는 듯한 움직임</u>을 보여줌
- 크게 기울어져 있으면 빨리 가고 작게 기울어져 있으면 느리게 감
- SGD와 비교하면 '지그재그 정도'가 덜하다.

### 6.1.5. AdaGrad

- **학습률 감소**(learning rate decay): 학습을 진행하면서 학습률을 점차 줄여가는 방법
- AdaGrad는 각각의 매개변수에 맞춤형 학습률 값을 만들어서, <u>개별 매개변수에 적응적으로(adaptive) 학습률을 조정</u>하면서 학습을 진행
- 매개변수의 원소 중에서 많이 움직인(크게 갱신된) 원소는 학습률이 낮아진다.
- 코드로 구현할 때는 0으로 나누는 사태를 막기 위해 1e-7이라는 작은 값을 더하는 부분이 있다.
- 최솟값을 향해 효율적으로 움직인다. 기울기가 커서 크게 움직였다면 그 큰 움직임에 비례해 갱신 정도도 큰 폭으로 작아지도록 조정되므로, 결국 지그재그 움직임이 줄어든다.

### 6.1.6. Adam

- 모멘텀과 AdaGrad 두 기법을 융합
- 또 하이퍼파라미터의 '편향 보정'도 진행됨
- <u>모멘텀과 비슷한 패턴으로 공이 그릇의 바닥을 구르듯 움직이되, 모멘텀 때보다 공의 좌우 흔들림이 적다. 이는 학습의 갱신 강도를 적응적으로 조정해서 얻는 혜택이다.</u>

### 6.1.7. 어느 갱신 방법을 이용할 것인가?

- SGD, 모멘텀, AdaGrad, Adam의 네 후보 중 모든 문제에서 항상 뛰어난 기법이라는 것은 (아직까진) 없다.
- 풀어야 할 문제가 무엇이냐에 따라 결과가 달라지고, (학습률 등의) 하이퍼파라미터를 어떻게 설정하느냐에 따라서도 달라진다.
- <u>일반적으로 SGD보다 다른 세 기법이 빠르게 학습하고, 때로는 최종 정확도도 높게 나타난다.</u>
- 각자의 상황을 고려해 여러 가지로 시도해 보자.



## 6.2. 가중치의 초깃값

- 가중치의 초깃값을 무엇으로 설정하느냐가 신경망 학습의 성패를 가르는 일이 자주 있음
- **가중치 감소**(weight decay): 가중치 매개변수의 값이 작아지도록 학습하는 방법. 가중치 값을 작게 하여 오버피팅을 억제해 범용 성능을 높이는 테크닉.
- 가중치를 작게 만들고 싶으면 초깃값도 최대한 작은 값에 시작한다.
- 하지만 가중치의 초깃값을 (모두 0으로 하는 것처럼) 균일한 값으로 설정하면 안된다. 오차역전파법에서 모든 가중치의 값이 똑같이 갱신되기 때문이다. 이는 가중치를 여러 개 갖는 의미를 사라지게 한다. <u>'가중치가 고르게 되어버리는 상황'을 막으려면(정확히는 가중치의 대칭적인 구조를 무너뜨리려면) 초깃값을 무작위로 설정해야 한다.</u>

- <u>가중치 초깃값의 표준편차가 너무 크면(분포가 너무 넓으면)</u> 활성화 함수의 출력 데이터가 0과 1에 치우쳐 분포하게 되어 그 미분이 0에 다가간다. -> <u>**기울기 소실**(gradient vanishing) 문제 발생</u>
- <u>가중치 초깃값의 표준편차가 너무 작으면(분포가 너무 좁으면)</u> 활성화 함수의 출력 데이터가 0.5 부근에 집중되어 기울기 소실 문제는 일어나지 않지만, 다수의 뉴런이 거의 같은 값을 출력하고 있으므로 뉴런을 여러 개 둔 의미가 없어진다. -> <u>**표현력 제한** 문제 발생</u>
- <u>즉, 층과 층 사이에 흐르는 데이터가 적당히 퍼져 있어야 신경망 학습이 효율적으로 이뤄진다.</u>
- Sigmoid 함수, Tanh 함수는 좌우 대칭이라 중앙 부근이 선형인 함수로 볼 수 있기 때문에 활성화 함수가 선형인 것을 전제로 이끈 결과인 Xavier 초깃값을 사용한다. 반면 ReLU 함수를 이용할 때는 ReLU 함수에 특화된 초깃값인 He 초깃값을 이용한다.
- **Xavier 초깃값**: 앞 계층의 노드가 n개일 때 표준편차가 1/root(n)인 정규분포를 사용한다. 앞 층에 노드가 많을수록 대상 노드의 초깃값으로 설정하는 가중치가 좁게 퍼진다. 현재 일반적인 딥러닝 프레임워크들은 Xavier 초깃값을 표준적으로 이용하고 있다. 예를 들어 카페(Caffe) 프레임워크는 가중치 초깃값을 설정할 때 인수로 xavier를 지정할 수 있다.
- **He 초깃값**: 앞 계층의 노드가 n개일 때 표준편차가 root(2/n)인 정규분포를 사용한다. Xavier 초깃값은 1/root(n)이었는데, ReLU는 음의 영역이 0이라서 더 넓게 분포시키기 위해 2배의 계수가 필요하다고 (직감적으로) 해석할 수 있다.

- 정리! <u>활성화 함수로 Sigmoid 함수나 Tanh 함수 등의 S자 모양 곡선을 사용할 때는 Xavier 초깃값을, ReLU 함수를 사용할 때는 He 초깃값을 사용한다.</u>

  | 활성화 함수             | 가중치 초깃값 | 표준편차  |
  | ----------------------- | ------------- | --------- |
  | Sigmoid 함수, Tanh 함수 | Xavier 초깃값 | 1/root(n) |
  | ReLU 함수               | He 초깃값     | root(2/n) |



## 6.3. 배치 정규화(batch normalization)

- **배치 정규화**: 각 층에서의 활성화값이 적당히 분포되도록 조정하는 것
- 많은 연구자와 기술자가 즐겨 사용하고 있으며, 실제로 기계학습 콘테스트의 결과를 보면 배치 정규화를 사용하여 뛰어난 결과를 달성한 예가 많다.
- 배치 정규화의 장점
  - 학습을 빨리 진행할 수 있다. (학습 속도 개선)
  - 가중치 초깃값에 크게 의존하지 않는다. (골치 아픈 초깃값 선택 문제여 안녕!)
  - 오버피팅을 억제한다. (드롭아웃 등의 필요성 감소)
- 배치 정규화는 학습 시 미니배치를 단위로, 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화한다. 또, 이 정규화된 데이터에 고유한 확대(scale)와 이동(shift) 변환을 수행한다. 처음에는 확대값 = 1, 이동값 = 0부터 시작하고, 학습하면서 적합한 값으로 조정해간다.
- 이러한 처리를 하는 '배치 정규화 계층'을 신경망의 활성화 함수의 앞 혹은 뒤에 삽입하여, 순전파 때 적용된다. -> 데이터 분포가 덜 치우치게 만든다.



## 6.4. 바른 학습을 위해

- **오버피팅**: 신경망이 훈련 데이터에만 지나치게 적응되어 그 외에 데이터에는 제대로 대응하지 못하는 상태. 즉 훈련 데이터에 대한 정확도가 지나치게 높아서 시험 데이터에 대한 정확도와 크게 벌어지는 상태.
- 오버피팅이 일어나는 경우
  - 매개변수가 많고 표현력이 높은 모델
  - 훈련 데이터가 적음
- 오버피팅 억제 방향: <u>훈련 데이터에 대한 정확도가 100%에 도달하지 않게 하면서, 훈련 데이터와 시험 데이터에 대한 정확도 차이를 줄여야 한다.</u>
- 오버피팅을 억제하는 정규화 기술
  - **가중치 감소**: 학습 과정에서 <u>큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과</u>하여 오버피팅을 억제한다. 오버피팅은 가중치 매개변수의 값이 커서 발생하는 경우가 많기 때문이다. 예를 들어 손실 함수에 가중치의 L2 norm을 더하여 가중치가 커지는 것을 억제한다.
  - **드롭아웃**: 신경망 모델이 복잡해져서 가중치 감소만으로는 대응하기 어려워질 때 드롭아웃 기법을 사용한다. 드롭아웃은 <u>뉴런을 임의로 삭제하면서 학습</u>하는 방법이다. 훈련 때는 삭제할 은닉층의 뉴런을 무작위로 선택하여 신호 전달을 차단하고, 시험 때는 모든 뉴런에 신호를 전달한다.



## 6.5. 적절한 하이퍼파라미터 값 찾기

- 신경망의 하이퍼파라미터로는 각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 학습률과 가중치 감소 등이 있다. 하이퍼파라미터의 값을 적절히 설정하지 않으면 모델의 성능이 크게 떨어진다. 하이퍼파라미터의 값을 최대한 효율적으로 탐색하는 방법을 알아 보자.

### 6.5.1. 검증 데이터

- 하이퍼파라미터를 설정하고 검증할 때는 시험 데이터를 사용하면 안된다. 하이퍼파라미터 값이 시험 데이터에 오버피팅되기 때문이다. -> 따라서 하이퍼파라미터를 조정할 때는 하이퍼파라미터 전용 확인 데이터가 필요한데 이것을 **검증 데이터**(validation data)라고 부르며, 하이퍼파라미터의 적절성을 평가하는 데이터다.

  | 데이터 분리 | 사용처                                                       |
  | ----------- | ------------------------------------------------------------ |
  | 훈련 데이터 | 매개변수(가중치, 편향) 학습                                  |
  | 검증 데이터 | 하이퍼파라미터 성능 평가                                     |
  | 시험 데이터 | 신경망의 범용 성능 평가 (이상적으로는 마지막에 한 번만 사용) |

### 6.5.2. 하이퍼파라미터 최적화

- 하이퍼파라미터 최적화의 순서
  0. 하이퍼파라미터 값의 범위를 대략적으로 설정한다. (10<sup>-3</sup>~10<sup>3</sup>과 같이 '10의 거듭제곱' 단위, 즉 로그 스케일(log scale)로 범위를 지정한다.)
  1. 설정된 범위에서 하이퍼파라미터의 값을 무작위로 추출한다.
  2. 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가한다. (단, 1회 평가에 걸리는 시간을 단축하기 위하여 에폭은 작게 설정한다.)
  3. 1단계와 2단계를 특정 횟수(100회 등) 반복하며, 그 정확도의 결과를 보고 하이퍼파라미터의 범위를 좁힌다.
- 이상을 반복하여 하이퍼파라미터의 범위를 좁혀가고, 어느 정도 좁아지면 그 압축한 범위에서 값을 하나 골라낸다.



---

## 메모

- AdaGrad는 과거의 기울기를 제곱하여 계속 더해간다. 그래서 학습을 진행할수록 갱신 강도가 약해지며, 실제로 무한히 계속 학습한다면 어느 순간 갱신량이 0이 되어 전혀 갱신되지 않게 된다. 이 문제를 개선한 기법이 **RMSProp**이다. PMSProp은 과거의 모든 기울기를 균일하게 더해가는 것이 아니라, 먼 과거의 기울기는 서서히 잊고 새로운 기울기 정보를 크게 반영한다. 이를 **지수이동평균**(EMA: Exponential Moving Average)이라 하여, 과거 기울기의 반영 규모를 기하급수적으로 감소시킨다.
- 활성화 함수로 Sigmoid 함수 대신 **Tanh(하이퍼볼릭 탄젠트) 함수**를 이용하면 활성화값 분포의 일그러짐이 개선된다. Tanh 함수도 Sigmoid 함수와 같은 'S'자 모양 곡선인데, Sigmoid 함수는 (x, y) = (0, 0.5)에서 대칭인 반면 Tanh 함수는 (x, y) = (0, 0)에서 대칭인 S 곡선이다. <u>활성화 함수용으로는 원점에서 대칭인 함수가 바람직하다</u>고 알려져 있다.
- 정규화 항으로 사용되는 norm의 종류
  - **L1 norm** (Manhattan norm): |x<sub>1</sub>| + |x<sub>2</sub>| + ... + |x<sub>n</sub>|
  - **L2 norm** (Euclidean norm) : root(x<sub>1</sub><sup>2</sup> + x<sub>2</sub><sup>2</sup> + ... + x<sub>n</sub><sup>2</sup>)
  - **L∞ norm** (Max norm): max(|x<sub>1</sub>|, |x<sub>2</sub>|, ... , |x<sub>n</sub>|)

- **앙상블 학습**(ensemble learning): 기계학습에서는 앙상블 학습을 애용하는데, 앙상블 학습은 <u>개별적으로 학습시킨 여러 모델의 출력을 평균 내거나 투표(voting)하는 등으로 추론</u>하는 방식이다. 예를 들면 같은 (혹은 비슷한) 구조의 네트워크를 5개 준비하여 따로따로 학습시키고, 시험 때는 그 5개의 출력을 평균 내어 답하는 것이다. 앙상블 학습을 수행하면 신경망의 정확도가 몇% 정도 개선된다는 것이 실험적으로 알려져 있다. 앙상블 학습은 드롭아웃과 밀접하다. 드롭아웃이 학습 때 뉴런을 무작위로 삭제하는 행위를 매번 다른 모델을 학습시키는 것으로 해석할 수 있고, 추론 때 뉴런의 출력에 삭제한 비율(이를 테면 0.5 등)을 곱함으로써 앙상블 학습에서 여러 모델의 평균을 내는 것과 같은 효과를 얻을 수 있기 때문이다. 즉, 드롭아웃은 앙상블 학습과 같은 효과를 (대략) 하나의 네트워크로 구현했다고 생각할 수 있다.

- 위에서 설명한 하이퍼파라미터 최적화 방법은 과학이라기보다는 수행자의 지혜와 직관에 의존한다는 느낌이 드는 실용적인 방법이다. **베이즈 최적화**(Bayesian optimization)는 베이즈 정리(Bayes' theorem)를 중심으로 한 수학 이론을 구사하여 더 엄밀하고 효율적인 최적화를 수행한다.

